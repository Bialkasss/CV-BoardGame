{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading area detected.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_trading_area(frame):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (9, 9), 2)\n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        if len(approx) == 4:  # Detect rectangles\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            aspect_ratio = w / float(h)\n",
    "            if 0.95 <= aspect_ratio <= 1.05 and cv2.isContourConvex(approx):\n",
    "                return x, y, w, h  # Return bounding box of the trading area\n",
    "\n",
    "    return None\n",
    "\n",
    "def detect_circles(frame, roi):\n",
    "    x, y, w, h = roi\n",
    "    roi_frame = frame[y:y+h, x:x+w]\n",
    "    gray_roi = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect circles using HoughCircles\n",
    "    circles = cv2.HoughCircles(\n",
    "        gray_roi, cv2.HOUGH_GRADIENT, dp=1, minDist=20,\n",
    "        param1=50, param2=30, minRadius=5, maxRadius=50\n",
    "    )\n",
    "    return circles, roi_frame\n",
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    trading_area = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if trading_area is None:\n",
    "            trading_area = detect_trading_area(frame)\n",
    "            if trading_area:\n",
    "                print(\"Trading area detected.\")\n",
    "            else:\n",
    "                print(\"No trading area detected. Skipping frame.\")\n",
    "                continue\n",
    "\n",
    "        # Detect circles in the trading area\n",
    "        circles, roi_frame = detect_circles(frame, trading_area)\n",
    "        \n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            for circle in circles[0, :]:\n",
    "                center = (circle[0], circle[1])\n",
    "                radius = circle[2]\n",
    "                # Draw the circle\n",
    "                cv2.circle(roi_frame, center, radius, (0, 255, 0), 2)\n",
    "                cv2.circle(roi_frame, center, 2, (0, 0, 255), 3)\n",
    "            # Display message on video\n",
    "            cv2.putText(frame, \"Trading is happening!\", (50, 50), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Draw the trading area on the original frame\n",
    "        x, y, w, h = trading_area\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        cv2.imshow(\"Trading Area Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "process_video('./materials/E2-trading,lis,wilk.MP4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_black_area(frame):\n",
    "    \"\"\"\n",
    "    Detect the black trading area in the top-right corner of the frame.\n",
    "    \"\"\"\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding to isolate dark areas\n",
    "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Focus only on the top-right part of the frame (trading area is expected here)\n",
    "    height, width = thresh.shape\n",
    "    roi = thresh[0:height//2, width//2:]  # Top-right half\n",
    "\n",
    "    # Find contours in the ROI\n",
    "    contours, _ = cv2.findContours(roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        # Filter for large enough contours\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 500:  # Minimum area to qualify as a trading area\n",
    "            # Get bounding box\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            return x + width//2, y, w, h  # Adjust x-coordinates to the full frame\n",
    "\n",
    "    return None\n",
    "\n",
    "def detect_circles(frame, roi):\n",
    "    \"\"\"\n",
    "    Detect circular shapes within the trading area (ROI).\n",
    "    \"\"\"\n",
    "    x, y, w, h = roi\n",
    "    roi_frame = frame[y:y+h, x:x+w]\n",
    "    gray_roi = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use HoughCircles to detect circles\n",
    "    circles = cv2.HoughCircles(\n",
    "        gray_roi, cv2.HOUGH_GRADIENT, dp=1.2, minDist=20,\n",
    "        param1=50, param2=30, minRadius=5, maxRadius=50\n",
    "    )\n",
    "\n",
    "    return circles, roi_frame\n",
    "\n",
    "def process_video(video_path):\n",
    "    \"\"\"\n",
    "    Process the video to detect the trading area and identify trading events.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect the black trading area\n",
    "        trading_area = detect_black_area(frame)\n",
    "        if trading_area:\n",
    "            x, y, w, h = trading_area\n",
    "\n",
    "            # Detect circles in the trading area\n",
    "            circles, roi_frame = detect_circles(frame, trading_area)\n",
    "\n",
    "            # Draw the detected trading area\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            # If circles are detected, mark them and display the trading message\n",
    "            if circles is not None:\n",
    "                circles = np.uint16(np.around(circles))\n",
    "                for circle in circles[0, :]:\n",
    "                    cx, cy, radius = circle\n",
    "                    # Draw the circle on the ROI\n",
    "                    cv2.circle(roi_frame, (cx, cy), radius, (0, 255, 0), 2)\n",
    "                    cv2.circle(roi_frame, (cx, cy), 2, (0, 0, 255), 3)\n",
    "\n",
    "                # Display the message for trading detection\n",
    "                cv2.putText(frame, \"Trading is happening!\", (50, 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame with detection\n",
    "        cv2.imshow(\"Trading Detection\", frame)\n",
    "\n",
    "        # Break on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "process_video('./materials/E2-trading,lis,wilk.MP4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# Buffer to track detected circles across frames\n",
    "circle_buffer = deque(maxlen=10)  # Store the last 10 frames\n",
    "\n",
    "def detect_black_area(frame):\n",
    "    \"\"\"\n",
    "    Detect the top part of the black trading area in the frame.\n",
    "    \"\"\"\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding to isolate dark areas\n",
    "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Focus on the top-right part of the frame (trading area is expected here)\n",
    "    height, width = thresh.shape\n",
    "    roi = thresh[0:height//2, width//2:]  # Top-right half\n",
    "\n",
    "    # Find contours in the ROI\n",
    "    contours, _ = cv2.findContours(roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        # Filter for large enough contours\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 500:  # Minimum area to qualify as a trading area\n",
    "            # Get bounding box\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            return x + width//2, y, w, h  # Adjust x-coordinates to the full frame\n",
    "\n",
    "    return None\n",
    "\n",
    "def detect_circles(frame, roi):\n",
    "    \"\"\"\n",
    "    Detect circular shapes within the trading area (ROI).\n",
    "    \"\"\"\n",
    "    x, y, w, h = roi\n",
    "    roi_frame = frame[y:y+h, x:x+w]\n",
    "    gray_roi = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use HoughCircles to detect circles\n",
    "    circles = cv2.HoughCircles(\n",
    "        gray_roi, cv2.HOUGH_GRADIENT, dp=1.2, minDist=20,\n",
    "        param1=50, param2=30, minRadius=10, maxRadius=50  # Tuned for tokens\n",
    "    )\n",
    "\n",
    "    if circles is not None:\n",
    "        # Filter out dice by ensuring circularity and size constraints\n",
    "        valid_circles = []\n",
    "        for circle in np.uint16(np.around(circles))[0, :]:\n",
    "            cx, cy, radius = circle\n",
    "            # Circularity and size check\n",
    "            if 15 <= radius <= 35:  # Tokens typically fall within this size range\n",
    "                valid_circles.append((cx, cy, radius))\n",
    "        return valid_circles, roi_frame\n",
    "\n",
    "    return None, roi_frame\n",
    "\n",
    "def is_trading(circles):\n",
    "    \"\"\"\n",
    "    Check if trading is happening by ensuring circles are detected consistently.\n",
    "    \"\"\"\n",
    "    global circle_buffer\n",
    "    circle_buffer.append(len(circles) if circles else 0)\n",
    "\n",
    "    # Check if circles have been detected consistently for 5+ frames\n",
    "    return sum(1 for count in circle_buffer if count > 0) >= 5\n",
    "\n",
    "def process_video(video_path):\n",
    "    \"\"\"\n",
    "    Process the video to detect the trading area and identify trading events.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect the black trading area\n",
    "        trading_area = detect_black_area(frame)\n",
    "        if trading_area:\n",
    "            x, y, w, h = trading_area\n",
    "\n",
    "            # Detect circles in the trading area\n",
    "            circles, roi_frame = detect_circles(frame, trading_area)\n",
    "\n",
    "            # Draw the detected trading area\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            # If circles are detected, mark them\n",
    "            if circles:\n",
    "                for cx, cy, radius in circles:\n",
    "                    # Draw the circle on the ROI\n",
    "                    cv2.circle(roi_frame, (cx, cy), radius, (0, 255, 0), 2)\n",
    "                    cv2.circle(roi_frame, (cx, cy), 2, (0, 0, 255), 3)\n",
    "\n",
    "            # Check if trading is happening\n",
    "            if circles and is_trading(circles):\n",
    "                # Display the message for trading detection\n",
    "                cv2.putText(frame, \"Trading is happening!\", (50, 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame with detection\n",
    "        cv2.imshow(\"Trading Detection\", frame)\n",
    "\n",
    "        # Break on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "process_video('./materials/E2-trading,lis,wilk.MP4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# Buffer to track detected circles across frames\n",
    "circle_buffer = deque(maxlen=30)  # Store the last 10 frames\n",
    "\n",
    "def detect_black_area(frame):\n",
    "    \"\"\"\n",
    "    Detect the trading area in the top-right corner of the frame.\n",
    "    Ensures the detected area is sufficiently large and matches expected proportions.\n",
    "    \"\"\"\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding to isolate dark areas\n",
    "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Focus on the top-right part of the frame (trading area is expected here)\n",
    "    height, width = thresh.shape\n",
    "    roi = thresh[0:height//2, width//2:]  # Top-right half\n",
    "\n",
    "    # Find contours in the ROI\n",
    "    contours, _ = cv2.findContours(roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        # Filter for sufficiently large contours\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area < 1000:  # Minimum size to consider as the trading area\n",
    "            continue\n",
    "\n",
    "        # Get bounding box of the contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Ensure the area matches the expected proportions\n",
    "        aspect_ratio = w / float(h)\n",
    "        if 0.8 <= aspect_ratio <= 1.2 and area > 1500:\n",
    "            return x + width//2, y, w, h  # Adjust x-coordinates to the full frame\n",
    "\n",
    "    return None\n",
    "\n",
    "def detect_circles(frame, roi):\n",
    "    \"\"\"\n",
    "    Detect circular shapes within the trading area (ROI).\n",
    "    Uses circularity and size constraints to filter out dice.\n",
    "    \"\"\"\n",
    "    x, y, w, h = roi\n",
    "    roi_frame = frame[y:y+h, x:x+w]\n",
    "    gray_roi = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use HoughCircles to detect circles\n",
    "    circles = cv2.HoughCircles(\n",
    "        gray_roi, cv2.HOUGH_GRADIENT, dp=1.2, minDist=20,\n",
    "        param1=50, param2=30, minRadius=10, maxRadius=35  # Tuned for tokens\n",
    "    )\n",
    "\n",
    "    if circles is not None:\n",
    "        # Filter circles based on size and circularity\n",
    "        valid_circles = []\n",
    "        for circle in np.uint16(np.around(circles))[0, :]:\n",
    "            cx, cy, radius = circle\n",
    "            if 15 <= radius <= 35:  # Tokens fall within this size range\n",
    "                # Compute circularity: (4 * π * area) / perimeter^2\n",
    "                contour_area = np.pi * (radius**2)\n",
    "                perimeter = 2 * np.pi * radius\n",
    "                circularity = (4 * np.pi * contour_area) / (perimeter**2)\n",
    "                if circularity > 0.7:  # Ensure it’s circular\n",
    "                    valid_circles.append((cx, cy, radius))\n",
    "        return valid_circles, roi_frame\n",
    "\n",
    "    return None, roi_frame\n",
    "\n",
    "def is_trading(circles):\n",
    "    \"\"\"\n",
    "    Check if trading is happening by ensuring circles are detected consistently.\n",
    "    \"\"\"\n",
    "    global circle_buffer\n",
    "    circle_buffer.append(len(circles) if circles else 0)\n",
    "\n",
    "    # Check if circles have been detected consistently for 5+ frames\n",
    "    return sum(1 for count in circle_buffer if count > 0) >= 5\n",
    "\n",
    "def process_video(video_path):\n",
    "    \"\"\"\n",
    "    Process the video to detect the trading area and identify trading events.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect the black trading area\n",
    "        trading_area = detect_black_area(frame)\n",
    "        if trading_area:\n",
    "            x, y, w, h = trading_area\n",
    "\n",
    "            # Detect circles in the trading area\n",
    "            circles, roi_frame = detect_circles(frame, trading_area)\n",
    "\n",
    "            # Draw the detected trading area\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            # If circles are detected, mark them\n",
    "            if circles:\n",
    "                for cx, cy, radius in circles:\n",
    "                    # Draw the circle on the ROI\n",
    "                    cv2.circle(roi_frame, (cx, cy), radius, (0, 255, 0), 2)\n",
    "                    cv2.circle(roi_frame, (cx, cy), 2, (0, 0, 255), 3)\n",
    "\n",
    "            # Check if trading is happening\n",
    "            if circles and is_trading(circles):\n",
    "                # Display the message for trading detection\n",
    "                cv2.putText(frame, \"Trading is happening!\", (50, 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame with detection\n",
    "        cv2.imshow(\"Trading Detection\", frame)\n",
    "\n",
    "        # Break on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "process_video('./materials/E2-trading,lis,wilk.MP4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# Buffer to track detected tokens across frames\n",
    "circle_buffer = deque(maxlen=10)  # Store the last 10 frames\n",
    "\n",
    "\n",
    "def detect_black_area(frame):\n",
    "    \"\"\"\n",
    "    Detect the black trading area in the top-right corner of the frame.\n",
    "    Uses contours and mean intensity filtering to ensure robustness.\n",
    "    \"\"\"\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding to isolate dark areas\n",
    "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Focus on the top-right part of the frame (trading area is expected here)\n",
    "    height, width = thresh.shape\n",
    "    roi = thresh[0:height//2, width//2:]  # Top-right half\n",
    "\n",
    "    # Find contours in the ROI\n",
    "    contours, _ = cv2.findContours(roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        # Filter for sufficiently large contours\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area < 800:  # Minimum size to consider as the trading area\n",
    "            continue\n",
    "\n",
    "        # Get bounding box of the contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Check the mean intensity of the area to confirm it's black\n",
    "        mean_intensity = np.mean(gray[y:y+h, x+width//2:x+width//2+w])\n",
    "        if mean_intensity < 50:  # Black areas have low intensity\n",
    "            return x + width//2, y, w, h  # Adjust x-coordinates to the full frame\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_circles(frame, roi):\n",
    "    \"\"\"\n",
    "    Detect circular shapes within the trading area (ROI).\n",
    "    Uses circularity and size constraints to filter out dice.\n",
    "    \"\"\"\n",
    "    x, y, w, h = roi\n",
    "    roi_frame = frame[y:y+h, x:x+w]\n",
    "    gray_roi = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use HoughCircles to detect circles\n",
    "    circles = cv2.HoughCircles(\n",
    "        gray_roi, cv2.HOUGH_GRADIENT, dp=1.2, minDist=15,\n",
    "        param1=50, param2=20, minRadius=10, maxRadius=40  # Tuned for tokens\n",
    "    )\n",
    "\n",
    "    if circles is not None:\n",
    "        # Filter circles based on size and circularity\n",
    "        valid_circles = []\n",
    "        for circle in np.uint16(np.around(circles))[0, :]:\n",
    "            cx, cy, radius = circle\n",
    "            if 15 <= radius <= 35:  # Tokens fall within this size range\n",
    "                valid_circles.append((cx, cy, radius))\n",
    "        return valid_circles, roi_frame\n",
    "\n",
    "    return None, roi_frame\n",
    "\n",
    "\n",
    "def is_trading(circles):\n",
    "    \"\"\"\n",
    "    Check if trading is happening by ensuring circles are detected consistently.\n",
    "    \"\"\"\n",
    "    global circle_buffer\n",
    "    circle_buffer.append(len(circles) if circles else 0)\n",
    "\n",
    "    # Check if circles have been detected consistently for 5+ frames\n",
    "    return sum(1 for count in circle_buffer if count > 0) >= 5\n",
    "\n",
    "\n",
    "def process_video(video_path):\n",
    "    \"\"\"\n",
    "    Process the video to detect the trading area and identify trading events.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect the black trading area\n",
    "        trading_area = detect_black_area(frame)\n",
    "        if trading_area:\n",
    "            x, y, w, h = trading_area\n",
    "\n",
    "            # Detect circles in the trading area\n",
    "            circles, roi_frame = detect_circles(frame, trading_area)\n",
    "\n",
    "            # Draw the detected trading area\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            # If circles are detected, mark them\n",
    "            if circles:\n",
    "                for cx, cy, radius in circles:\n",
    "                    # Draw the circle on the ROI\n",
    "                    cv2.circle(roi_frame, (cx, cy), radius, (0, 255, 0), 2)\n",
    "                    cv2.circle(roi_frame, (cx, cy), 2, (0, 0, 255), 3)\n",
    "\n",
    "            # Check if trading is happening\n",
    "            if circles and is_trading(circles):\n",
    "                # Display the message for trading detection\n",
    "                cv2.putText(frame, \"Trading is happening!\", (50, 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame with detection\n",
    "        cv2.imshow(\"Trading Detection\", frame)\n",
    "\n",
    "        # Break on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "process_video('./materials/E1-trading,wilkx2.MP4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# Buffer to track tokens detected near the black area for consecutive frames\n",
    "trading_buffer = deque(maxlen=10)\n",
    "\n",
    "def detect_animal_tokens(frame):\n",
    "    \"\"\"\n",
    "    Detect animal tokens based on their distinct colors in the HSV color space.\n",
    "    Returns a list of bounding boxes around detected tokens.\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define color ranges for animal tokens (tune as needed)\n",
    "    color_ranges = [\n",
    "        {\"lower\": (25, 50, 50), \"upper\": (35, 255, 255)},  # Yellow tokens\n",
    "        {\"lower\": (100, 50, 50), \"upper\": (130, 255, 255)},  # Blue tokens\n",
    "        {\"lower\": (0, 50, 50), \"upper\": (10, 255, 255)},  # Red tokens\n",
    "        # Add more color ranges if needed\n",
    "    ]\n",
    "\n",
    "    tokens = []\n",
    "    for color in color_ranges:\n",
    "        mask = cv2.inRange(hsv, color[\"lower\"], color[\"upper\"])\n",
    "        # Find contours for the masked regions\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 300:  # Filter small noise\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                tokens.append((x, y, w, h))\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def is_near_black_area(frame, token):\n",
    "    \"\"\"\n",
    "    Check if the given token is near a black region.\n",
    "    \"\"\"\n",
    "    x, y, w, h = token\n",
    "    # Expand the ROI slightly around the token\n",
    "    margin = 10\n",
    "    roi = frame[max(0, y-margin):y+h+margin, max(0, x-margin):x+w+margin]\n",
    "\n",
    "    # Convert ROI to grayscale and check the mean intensity\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    mean_intensity = np.mean(gray_roi)\n",
    "    return mean_intensity < 50  # Black areas have low intensity\n",
    "\n",
    "\n",
    "def process_video(video_path):\n",
    "    \"\"\"\n",
    "    Process the video to detect animal tokens and identify trading events.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect animal tokens\n",
    "        tokens = detect_animal_tokens(frame)\n",
    "\n",
    "        # Check if any token is near a black area\n",
    "        trading_detected = False\n",
    "        for token in tokens:\n",
    "            if is_near_black_area(frame, token):\n",
    "                trading_detected = True\n",
    "                break\n",
    "\n",
    "        # Update the trading buffer\n",
    "        trading_buffer.append(trading_detected)\n",
    "\n",
    "        # Confirm trading if detected for 10 consecutive frames\n",
    "        if sum(trading_buffer) >= 10:\n",
    "            cv2.putText(frame, \"Trading is happening!\", (50, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Draw detected tokens\n",
    "        for token in tokens:\n",
    "            x, y, w, h = token\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Trading Detection\", frame)\n",
    "\n",
    "        # Break on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "process_video('./materials/E1-trading,wilkx2.MP4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "def detect_black_area(frame):\n",
    "    \"\"\"\n",
    "    Detect the black trading area in the frame.\n",
    "    This method assumes that the black area is the darkest region in the frame.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 500:  # Minimum size of the trading area\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            return x, y, w, h\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_dominant_color(frame, mask):\n",
    "    \"\"\"\n",
    "    Calculate the dominant color inside the masked region of the frame.\n",
    "    \"\"\"\n",
    "    mask_flat = mask.flatten()\n",
    "    frame_flat = frame.reshape((-1, 3))\n",
    "    color_mask = frame_flat[mask_flat == 255]\n",
    "\n",
    "    if color_mask.size == 0:\n",
    "        return (0, 0, 0)\n",
    "\n",
    "    dominant_color = mode(color_mask, axis=0, keepdims=False).mode\n",
    "    return tuple(map(int, dominant_color))\n",
    "\n",
    "def detect_circles_and_colors(frame, trading_area):\n",
    "    \"\"\"\n",
    "    Detect circular tokens and their colors in the frame.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (9, 9), 2)\n",
    "\n",
    "    # Use HoughCircles to detect circles\n",
    "    circles = cv2.HoughCircles(\n",
    "        blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=30,\n",
    "        param1=50, param2=30, minRadius=10, maxRadius=40\n",
    "    )\n",
    "\n",
    "    detected_tokens = []\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        for circle in circles[0, :]:\n",
    "            cx, cy, r = circle\n",
    "\n",
    "            # Create a mask for the circle\n",
    "            mask = np.zeros_like(gray, dtype=np.uint8)\n",
    "            cv2.circle(mask, (cx, cy), r, 255, -1)\n",
    "\n",
    "            # Get the dominant color within the circle\n",
    "            dominant_color = get_dominant_color(frame, mask)\n",
    "\n",
    "            # Check if the circle is near the trading area\n",
    "            x, y, w, h = trading_area\n",
    "            if x <= cx <= x + w and y <= cy <= y + h:\n",
    "                detected_tokens.append((cx, cy, r, dominant_color))\n",
    "\n",
    "    return detected_tokens\n",
    "\n",
    "def process_video(video_path):\n",
    "    \"\"\"\n",
    "    Process the video to detect tokens and check for trading events.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect the black trading area\n",
    "        trading_area = detect_black_area(frame)\n",
    "        if trading_area:\n",
    "            x, y, w, h = trading_area\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "            # Detect circles (tokens) and their colors\n",
    "            tokens = detect_circles_and_colors(frame, trading_area)\n",
    "\n",
    "            for cx, cy, r, color in tokens:\n",
    "                # Draw the circle and the dominant color\n",
    "                cv2.circle(frame, (cx, cy), r, (0, 255, 0), 2)\n",
    "                cv2.circle(frame, (cx, cy), 2, (0, 0, 255), 3)\n",
    "                cv2.putText(frame, f\"{color}\", (cx - 20, cy - 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Trading Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "# process_video(\"path_to_your_video.mp4\")\n",
    "\n",
    "# Example usage\n",
    "process_video('./materials/E1-trading,wilkx2.MP4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    \"\"\"\n",
    "    Preprocess the frame to enhance contrast for token detection.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    return blurred\n",
    "\n",
    "def detect_circles(frame):\n",
    "    \"\"\"\n",
    "    Detect circular tokens using HoughCircles.\n",
    "    \"\"\"\n",
    "    blurred = preprocess_frame(frame)\n",
    "\n",
    "    # Detect circles using HoughCircles\n",
    "    circles = cv2.HoughCircles(\n",
    "        blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=30,\n",
    "        param1=50, param2=30, minRadius=10, maxRadius=40\n",
    "    )\n",
    "\n",
    "    if circles is not None:\n",
    "        return np.uint16(np.around(circles))\n",
    "    return None\n",
    "\n",
    "def get_circle_color(frame, circle):\n",
    "    \"\"\"\n",
    "    Get the dominant color inside the detected circle.\n",
    "    \"\"\"\n",
    "    cx, cy, radius = circle\n",
    "    mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "    cv2.circle(mask, (cx, cy), radius, 255, -1)\n",
    "\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    masked_pixels = hsv_frame[mask == 255]\n",
    "\n",
    "    if len(masked_pixels) > 0:\n",
    "        # Get the average color in HSV space\n",
    "        avg_color = np.mean(masked_pixels, axis=0)\n",
    "        return avg_color\n",
    "    return None\n",
    "\n",
    "def is_token_color(color):\n",
    "    \"\"\"\n",
    "    Determine if the given color matches token colors.\n",
    "    \"\"\"\n",
    "    # Define HSV ranges for token colors\n",
    "    token_color_ranges = [\n",
    "        {\"lower\": (20, 100, 100), \"upper\": (30, 255, 255)},  # Example: Yellow\n",
    "        {\"lower\": (100, 100, 100), \"upper\": (140, 255, 255)},  # Example: Blue\n",
    "        {\"lower\": (0, 100, 100), \"upper\": (10, 255, 255)},  # Example: Red\n",
    "    ]\n",
    "\n",
    "    for color_range in token_color_ranges:\n",
    "        if all(color_range[\"lower\"][i] <= color[i] <= color_range[\"upper\"][i] for i in range(3)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def process_video(video_path):\n",
    "    \"\"\"\n",
    "    Process the video to detect tokens and identify trading events.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect circles\n",
    "        circles = detect_circles(frame)\n",
    "\n",
    "        if circles is not None:\n",
    "            for circle in circles[0, :]:\n",
    "                cx, cy, radius = circle\n",
    "\n",
    "                # Get the dominant color inside the circle\n",
    "                color = get_circle_color(frame, (cx, cy, radius))\n",
    "\n",
    "                if color is not None and is_token_color(color):\n",
    "                    # Draw the detected token\n",
    "                    cv2.circle(frame, (cx, cy), radius, (0, 255, 0), 2)\n",
    "                    cv2.circle(frame, (cx, cy), 2, (0, 0, 255), 3)\n",
    "\n",
    "                    # Display token detection\n",
    "                    cv2.putText(frame, \"Token\", (cx - 20, cy - 20),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Token Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "process_video('./materials/E1-trading,wilkx2.MP4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "def reorder_corners(corners):\n",
    "    sorted_corners = sorted(corners, key=lambda x: x[0])\n",
    "    top_left, top_right = sorted_corners[:2]\n",
    "    bottom_left, bottom_right = sorted_corners[2:]\n",
    "\n",
    "    if top_left[1] > top_right[1]:\n",
    "        top_left, top_right = top_right, top_left\n",
    "\n",
    "    if bottom_left[1] > bottom_right[1]:\n",
    "        bottom_left, bottom_right = bottom_right, bottom_left\n",
    "\n",
    "    return np.array([top_left, top_right, bottom_left, bottom_right])\n",
    "\n",
    "def detect_board(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (9, 9), 1)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    edges_closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "    contours, _ = cv2.findContours(edges_closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        epsilon = 0.05 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        if len(approx) == 4:\n",
    "            approx = reorder_corners(approx.reshape(4, 2))\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            aspect_ratio = w / float(h)\n",
    "            area = cv2.contourArea(contour)\n",
    "            if 0.8 <= aspect_ratio <= 1.2 and area > 50000:\n",
    "                return approx, x, y, w, h\n",
    "    return None, None, None, None, None\n",
    "\n",
    "def create_tracker(tracker_type=\"CSRT\"):\n",
    "    if tracker_type == \"CSRT\":\n",
    "        return cv2.TrackerCSRT_create()\n",
    "    elif tracker_type == \"KCF\":\n",
    "        return cv2.TrackerKCF_create()\n",
    "    return None\n",
    "\n",
    "def draw_bbox_with_area(frame, bbox, color=(255, 255, 255)):\n",
    "    p1 = (int(bbox[0]), int(bbox[1]))\n",
    "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "    cv2.rectangle(frame, p1, p2, color, 2, 1)\n",
    "    text_position = (p1[0], max(0, p1[1] - 10))\n",
    "    cv2.putText(frame, \"Dice\", text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1, cv2.LINE_AA)\n",
    "\n",
    "def get_dominant_color(image, mask):\n",
    "    colors = image[mask == 255]\n",
    "    if len(colors) == 0:\n",
    "        return (0, 0, 0)\n",
    "\n",
    "    colors = [tuple(color) for color in colors]\n",
    "    most_common_color = Counter(colors).most_common(1)[0][0]\n",
    "\n",
    "    return most_common_color\n",
    "\n",
    "def detect_circles_and_colors(frame, hsv_frame, thresholds):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (9, 9), 2)\n",
    "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=30, param1=200, param2=100, minRadius=10, maxRadius=100)\n",
    "\n",
    "    detected_tokens = []\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        for circle in circles[0, :]:\n",
    "            x, y, r = circle\n",
    "\n",
    "            # Create a circular mask for the detected circle\n",
    "            mask = np.zeros_like(gray, dtype=np.uint8)\n",
    "            cv2.circle(mask, (x, y), r, 255, -1)\n",
    "\n",
    "            # Get dominant color inside the circle\n",
    "            dominant_color = get_dominant_color(frame, mask)\n",
    "\n",
    "            # Determine animal type based on thresholds\n",
    "            for animal, (lower, upper) in thresholds.items():\n",
    "                if np.all(lower <= dominant_color) and np.all(dominant_color <= upper):\n",
    "                    detected_tokens.append((animal, (x, y, r), dominant_color))\n",
    "\n",
    "    return detected_tokens\n",
    "\n",
    "def detect_circles_and_dice_in_video(video_path, thresholds):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Detect animal tokens\n",
    "        detected_tokens = detect_circles_and_colors(frame, hsv_frame, thresholds)\n",
    "        for animal, (x, y, r), dominant_color in detected_tokens:\n",
    "            color = (0, 255, 0)\n",
    "            cv2.circle(frame, (x, y), r, color, 2)\n",
    "            label = f\"{animal}\"\n",
    "            cv2.putText(frame, label, (x - r, y - r - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Circles and Colors\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "animal_color_thresholds = {\n",
    "    \"rabbit\": (np.array([0, 50, 50]), np.array([10, 255, 255])),\n",
    "    \"sheep\": (np.array([20, 50, 50]), np.array([30, 255, 255])),\n",
    "    \"pig\": (np.array([30, 50, 50]), np.array([40, 255, 255])),\n",
    "    \"cow\": (np.array([0, 0, 50]), np.array([180, 50, 255])),\n",
    "    \"horse\": (np.array([50, 50, 50]), np.array([70, 255, 255]))\n",
    "}\n",
    "\n",
    "detect_circles_and_dice_in_video('./materials/E1.MP4', animal_color_thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Helper function to calculate the dominant color\n",
    "\n",
    "def get_dominant_color(image, mask):\n",
    "    colors = image[mask == 255]\n",
    "    if len(colors) == 0:\n",
    "        return (0, 0, 0)\n",
    "\n",
    "    colors = [tuple(color) for color in colors]\n",
    "    most_common_color = Counter(colors).most_common(1)[0][0]\n",
    "\n",
    "    return most_common_color\n",
    "\n",
    "# Function to detect circles and stabilize color classification\n",
    "def detect_circles_and_colors_stable(video_path, thresholds, stability_window=5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    circle_history = defaultdict(list)  # Store recent classifications per circle\n",
    "    stable_results = {}  # Final stabilized results\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (9, 9), 2)\n",
    "        circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=50, param1=70, param2=30, minRadius=10, maxRadius=100)\n",
    "\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            for i, circle in enumerate(circles[0, :]):\n",
    "                x, y, r = circle\n",
    "\n",
    "                # Create a circular mask for the detected circle\n",
    "                mask = np.zeros_like(gray, dtype=np.uint8)\n",
    "                cv2.circle(mask, (x, y), r, 255, -1)\n",
    "\n",
    "                # Get dominant color inside the circle\n",
    "                dominant_color = get_dominant_color(frame, mask)\n",
    "\n",
    "                # Determine animal type based on thresholds\n",
    "                detected_animal = None\n",
    "                for animal, (lower, upper) in thresholds.items():\n",
    "                    if np.all(lower <= dominant_color) and np.all(dominant_color <= upper):\n",
    "                        detected_animal = animal\n",
    "                        break\n",
    "\n",
    "                if detected_animal:\n",
    "                    circle_history[i].append(detected_animal)\n",
    "\n",
    "                    # Keep only the last 'stability_window' classifications\n",
    "                    if len(circle_history[i]) > stability_window:\n",
    "                        circle_history[i].pop(0)\n",
    "\n",
    "                    # Determine the most frequent classification\n",
    "                    most_stable_animal = Counter(circle_history[i]).most_common(1)[0][0]\n",
    "                    stable_results[i] = most_stable_animal\n",
    "\n",
    "                    # Draw the circle and label\n",
    "                    color = (0, 255, 0)\n",
    "                    cv2.circle(frame, (x, y), r, color, 2)\n",
    "                    cv2.putText(frame, most_stable_animal, (x - r, y - r - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Stabilized Animal Tokens\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "animal_color_thresholds = {\n",
    "    \"rabbit\": (np.array([0, 50, 50]), np.array([10, 255, 255])),\n",
    "    \"sheep\": (np.array([20, 50, 50]), np.array([30, 255, 255])),\n",
    "    \"pig\": (np.array([30, 50, 50]), np.array([40, 255, 255])),\n",
    "    \"cow\": (np.array([0, 0, 50]), np.array([180, 50, 255])),\n",
    "    \"horse\": (np.array([50, 50, 50]), np.array([70, 255, 255]))\n",
    "}\n",
    "\n",
    "detect_circles_and_colors_stable('./materials/E2.MP4', animal_color_thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Helper function to calculate the dominant color\n",
    "\n",
    "def get_dominant_color(image, mask):\n",
    "    colors = image[mask == 255]\n",
    "    if len(colors) == 0:\n",
    "        return (0, 0, 0)\n",
    "\n",
    "    colors = [tuple(color) for color in colors]\n",
    "    most_common_color = Counter(colors).most_common(1)[0][0]\n",
    "\n",
    "    return most_common_color\n",
    "\n",
    "# Function to detect circles and stabilize color classification\n",
    "\n",
    "def compute_circle_size_and_tolerance():\n",
    "    # Define circle size and tolerance (example: derived from your board logic)\n",
    "    circle_size = 50  # Average circle radius in pixels\n",
    "    tolerance = 0.07 * circle_size  # Example tolerance\n",
    "    return circle_size, tolerance\n",
    "\n",
    "def detect_circles_and_colors_stable(video_path, thresholds, stability_window=5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    circle_size, tolerance = compute_circle_size_and_tolerance()\n",
    "    circle_history = defaultdict(list)  # Store recent classifications per circle\n",
    "    stable_results = {}  # Final stabilized results\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (9, 9), 2)\n",
    "        circles = cv2.HoughCircles(\n",
    "            blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=50,\n",
    "            param1=70, param2=30,\n",
    "            minRadius=int(circle_size - tolerance),\n",
    "            maxRadius=int(circle_size + tolerance)\n",
    "        )\n",
    "\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            for i, circle in enumerate(circles[0, :]):\n",
    "                x, y, r = circle\n",
    "\n",
    "                # Create a circular mask for the detected circle\n",
    "                mask = np.zeros_like(gray, dtype=np.uint8)\n",
    "                cv2.circle(mask, (x, y), r, 255, -1)\n",
    "\n",
    "                # Get dominant color inside the circle\n",
    "                dominant_color = get_dominant_color(frame, mask)\n",
    "\n",
    "                # Determine animal type based on thresholds\n",
    "                detected_animal = None\n",
    "                for animal, (lower, upper) in thresholds.items():\n",
    "                    if np.all(lower <= dominant_color) and np.all(dominant_color <= upper):\n",
    "                        detected_animal = animal\n",
    "                        break\n",
    "\n",
    "                if detected_animal:\n",
    "                    circle_history[i].append(detected_animal)\n",
    "\n",
    "                    # Keep only the last 'stability_window' classifications\n",
    "                    if len(circle_history[i]) > stability_window:\n",
    "                        circle_history[i].pop(0)\n",
    "\n",
    "                    # Determine the most frequent classification\n",
    "                    most_stable_animal = Counter(circle_history[i]).most_common(1)[0][0]\n",
    "                    stable_results[i] = most_stable_animal\n",
    "\n",
    "                    # Draw the circle and label\n",
    "                    color = (0, 255, 0)\n",
    "                    cv2.circle(frame, (x, y), r, (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, most_stable_animal, (x - r, y - r - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    # Draw unclassified circles in red\n",
    "                    cv2.circle(frame, (x, y), r, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Stabilized Animal Tokens\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "animal_color_thresholds = {\n",
    "    \"rabbit\": (np.array([0, 50, 50]), np.array([10, 255, 255])),\n",
    "    \"sheep\": (np.array([20, 50, 50]), np.array([30, 255, 255])),\n",
    "    \"pig\": (np.array([30, 50, 50]), np.array([40, 255, 255])),\n",
    "    \"cow\": (np.array([0, 0, 50]), np.array([180, 50, 255])),\n",
    "    \"horse\": (np.array([50, 50, 50]), np.array([70, 255, 255]))\n",
    "}\n",
    "\n",
    "detect_circles_and_colors_stable('./materials/EExtra.MP4', animal_color_thresholds)\n",
    "\n",
    "# detect_circles_and_colors_debug('./materials/E2.MP4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detecting just the cirkles- tokens without naming etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to detect circles in a video\n",
    "\n",
    "def compute_circle_size_and_tolerance():\n",
    "    # Define circle size and tolerance (example: derived from your board logic)\n",
    "    circle_size = 50  # Average circle radius in pixels\n",
    "    tolerance = 0.07 * circle_size  # Example tolerance\n",
    "    return circle_size, tolerance\n",
    "\n",
    "def detect_circles(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    circle_size, tolerance = compute_circle_size_and_tolerance()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (9, 9), 2)\n",
    "        circles = cv2.HoughCircles(\n",
    "            blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=50,\n",
    "            param1=70, param2=30,\n",
    "            minRadius=int(circle_size - tolerance),\n",
    "            maxRadius=int(circle_size + tolerance)\n",
    "        )\n",
    "\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            for circle in circles[0, :]:\n",
    "                x, y, r = circle\n",
    "                # Draw the circle on the frame\n",
    "                cv2.circle(frame, (x, y), r, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Detected Circles\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# # Call the function to detect circles\n",
    "# detect_circles('./materials/E1.MP4')\n",
    "# detect_circles('./materials/E2.MP4')\n",
    "# detect_circles('./materials/EExtra.MP4')\n",
    "detect_circles('./materials/H1.MP4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more stabe version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmart\\AppData\\Local\\Temp\\ipykernel_31316\\3138658194.py:21: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  distance = np.sqrt((x_new - x_prev)**2 + (y_new - y_prev)**2)\n",
      "C:\\Users\\mmart\\AppData\\Local\\Temp\\ipykernel_31316\\3138658194.py:21: RuntimeWarning: invalid value encountered in sqrt\n",
      "  distance = np.sqrt((x_new - x_prev)**2 + (y_new - y_prev)**2)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to compute circle size and tolerance\n",
    "def compute_circle_size_and_tolerance():\n",
    "    circle_size = 50  # Average circle radius in pixels\n",
    "    tolerance = 0.07 * circle_size  # Example tolerance\n",
    "    return circle_size, tolerance\n",
    "\n",
    "# Function to stabilize circle detection with exponential moving average\n",
    "def stabilize_circles(new_circles, previous_circles, alpha=0.98, distance_threshold=20):\n",
    "    if previous_circles is None:\n",
    "        return new_circles\n",
    "\n",
    "    stabilized_circles = []\n",
    "    for new_circle in new_circles:\n",
    "        x_new, y_new, r_new = new_circle\n",
    "        matched = False\n",
    "        for prev_circle in previous_circles:\n",
    "            x_prev, y_prev, r_prev = prev_circle\n",
    "            distance = np.sqrt((x_new - x_prev)**2 + (y_new - y_prev)**2)\n",
    "            if distance < distance_threshold:\n",
    "                # Apply exponential moving average for stabilization\n",
    "                x_stabilized = alpha * x_prev + (1 - alpha) * x_new\n",
    "                y_stabilized = alpha * y_prev + (1 - alpha) * y_new\n",
    "                r_stabilized = alpha * r_prev + (1 - alpha) * r_new\n",
    "                stabilized_circles.append((x_stabilized, y_stabilized, r_stabilized))\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            stabilized_circles.append(new_circle)\n",
    "\n",
    "    return stabilized_circles\n",
    "\n",
    "# Function to detect circles in a video\n",
    "def detect_circles(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    circle_size, tolerance = compute_circle_size_and_tolerance()\n",
    "    previous_circles = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (9, 9), 2)\n",
    "        circles = cv2.HoughCircles(\n",
    "            blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=50,\n",
    "            param1=70, param2=30,\n",
    "            minRadius=int(circle_size - tolerance),\n",
    "            maxRadius=int(circle_size + tolerance)\n",
    "        )\n",
    "\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))[0, :]\n",
    "            stabilized_circles = stabilize_circles(circles, previous_circles)\n",
    "            previous_circles = stabilized_circles\n",
    "\n",
    "            for circle in stabilized_circles:\n",
    "                x, y, r = map(int, circle)\n",
    "                # Draw the circle on the frame\n",
    "                cv2.circle(frame, (x, y), r, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Stabilized Circles\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# # Call the function to detect circles\n",
    "# detect_circles('./materials/E1.MP4')\n",
    "detect_circles('./materials/E2.MP4')\n",
    "# detect_circles('./materials/EExtra.MP4')\n",
    "# detect_circles('./materials/H1.MP4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
